\documentclass[a4paper,14pt,russian]{extreport}
 
\usepackage{extsizes}
\usepackage{cmap} % для кодировки шрифтов в pdf
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
%\usepackage{pscyr} % набор красивых шрифтов
 
\usepackage[dvips]{graphicx} % для вставки картинок
\graphicspath{{images/}}
\usepackage{amssymb,amsfonts,amsmath,amsthm} % математические дополнения от АМС
\usepackage{indentfirst} % отделять первую строку раздела абзацным отступом тоже
\usepackage[usenames,dvipsnames]{color} % названия цветов
\usepackage{makecell}
\usepackage{multirow} % улучшенное форматирование таблиц
\usepackage{ulem} % подчеркивания
 
\linespread{1.3} % полуторный интервал
\renewcommand{\rmdefault}{ftm} % Times New Roman
\frenchspacing

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage}
\fancyheadoffset{0mm}
\fancyfootoffset{0mm}
\setlength{\headheight}{17pt}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\fancypagestyle{plain}{ 
    \fancyhf{}
    \rhead{\thepage}}
\setcounter{page}{1} % начать нумерацию страниц с №1

\usepackage[tableposition=top]{caption}
\usepackage{subcaption}
\DeclareCaptionLabelFormat{gostfigure}{Рисунок #2}
\DeclareCaptionLabelFormat{gosttable}{Таблица #2}
\DeclareCaptionLabelSeparator{gost}{~---~}
\captionsetup{labelsep=gost}
\captionsetup[figure]{labelformat=gostfigure}
\captionsetup[table]{labelformat=gosttable}
\renewcommand{\thesubfigure}{\asbuk{subfigure}}

\usepackage{titlesec}
\titleformat{\chapter}[display]
    {\filcenter}
    {\MakeUppercase{\chaptertitlename} \thechapter}
    {8pt}
    {\bfseries}{}
\titleformat{\section}
    {\normalsize\bfseries}
    {\thesection}
    {1em}{}
\titleformat{\subsection}
    {\normalsize\bfseries}
    {\thesubsection}
    {1em}{}
     
% Настройка вертикальных и горизонтальных отступов
\titlespacing*{\chapter}{0pt}{-30pt}{8pt}
\titlespacing*{\section}{\parindent}{*4}{*4}
\titlespacing*{\subsection}{\parindent}{*4}{*4}

\usepackage{geometry}
\geometry{left=3cm}
\geometry{right=1.5cm}
\geometry{top=2.4cm}
\geometry{bottom=2.4cm}

\usepackage{enumitem}
\makeatletter
    \AddEnumerateCounter{\asbuk}{\@asbuk}{м)}
\makeatother
\setlist{nolistsep}
\renewcommand{\labelitemi}{-}
\renewcommand{\labelenumi}{\asbuk{enumi})}
\renewcommand{\labelenumii}{\arabic{enumii})}

\usepackage{tocloft}
\renewcommand{\cfttoctitlefont}{\hspace{0.38\textwidth} \bfseries\MakeUppercase}
\renewcommand{\cftbeforetoctitleskip}{-1em}
\renewcommand{\cftaftertoctitle}{\mbox{}\hfill \\ \mbox{}\hfill{\footnotesize Стр.}\vspace{-2.5em}}
\renewcommand{\cftchapfont}{\normalsize\bfseries \MakeUppercase{\chaptername} }
\renewcommand{\cftsecfont}{\hspace{31pt}}
\renewcommand{\cftsubsecfont}{\hspace{11pt}}
\renewcommand{\cftbeforechapskip}{1em}
\renewcommand{\cftparskip}{-1mm}
\renewcommand{\cftdotsep}{1}
\setcounter{tocdepth}{2} % задать глубину оглавления — до subsection включительно

\newcommand{\empline}{\mbox{}\newline}
\newcommand{\likechapterheading}[1]{ 
    \begin{center}
    \textbf{\MakeUppercase{#1}}
    \end{center}
    \empline}
    
\makeatletter
    \renewcommand{\@dotsep}{2}
    \newcommand{\l@likechapter}[2]{{\bfseries\@dottedtocline{0}{0pt}{0pt}{#1}{#2}}}
\makeatother
\newcommand{\likechapter}[1]{    
    \likechapterheading{#1}    
    \addcontentsline{toc}{likechapter}{\MakeUppercase{#1}}}

\usepackage[square,numbers,sort&compress]{natbib}
\renewcommand{\bibnumfmt}[1]{#1.\hfill} % нумерация источников в самом списке — через точку
\renewcommand{\bibsection}{\likechapter{Список литературы}} % заголовок специального раздела
\setlength{\bibsep}{0pt}

\parindent = 1cm

\begin{document}
% НАЧАЛО ТИТУЛЬНОГО ЛИСТА
\begin{center}
\hfill \break
\large{МИНОБРНАУКИ РОССИИ}\\
\footnotesize{ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ}\\ 
\small{\textbf{«МОСКОВСКИЙ ФИЗИКО-ТЕХНИЧЕСКИЙ ИНСТИТУТ»}}\\
\normalsize{Факультет управления и прикладной математики}\\
\normalsize{Кафедра системного программирования}\\
\hfill\break
\hfill \break
\hfill \break
\large{Исследование возможностей распараллеливания алгоритмов решения целочисленных линейных неравенств на GPU}\\
\hfill \break
\hfill \break
\hfill \break
\normalsize{Бакалаврский диплом\\
\hfill \break
Направление подготовки 010400 «Прикладные математика и информатика»}\\
\hfill \break
\hfill \break
\end{center}
 
\normalsize{ \hspace{28pt} Допущено к защите в ГЭК  20.06.2017} \hfill \break
\hfill \break
 
\normalsize{ 
\begin{tabular}{cccc}
Зав.кафедрой & \underline{\hspace{3cm}} &  д.физ.-мат.н.,  проф. & А.И. Аветисян \\
Обучающийся & \underline{\hspace{3cm}} & & В.В. Швецова \\
Руководитель & \underline{\hspace{3cm}}& к.физ.-мат.н.&  А.С. Камкин \\
\end{tabular}
}\\
\hfill \break
\hfill \break
\begin{center} Долгопрудный 2017 \end{center}
\thispagestyle{empty} % выключаем отображение номера для этой страницы
 
% КОНЕЦ ТИТУЛЬНОГО ЛИСТА
 
\newpage
     
    \tableofcontents % Вывод содержания
\newpage
 
\newpage


\chapter{Введение}

\section{Актуальность}

Работа является прикладным исследование в области массивно параллельного программирования с использованием технологии CUDA, а также в области целочисленного программирования и программирования в ограничениях.
\par Данная работа является прикладным исследованием в пересечении областей смешанного целочисленного программирования (англ. mixed integer programming) и программирования в ограничениях (англ. constraint programming). Так как многие важные задачи сводятся к задачам разрешения ограничений (англ. constraint satisfaction problem), методам разрешения ограничений уделяется немало внимания \cite{dechter}, \cite{freuder}, \cite{tsang}. 
\par Целочисленное и смешанное целочисленное программирование появилось в 50-60-х, когда выяснилось, что задачи смешанного целочисленного программирования часто возникают в различных практических задачах и стало актуальным их эффективное решение \cite{markowitz_manne}.
\par Впервые понятие общих ограничений, т.е не только линейных неравентв, было использовано Sutherland \cite{sutherland} в его проекте интерактивной системы Sketchpad, предоставляющей пользователю рабочий интерфейс для набросков или эскизов при помощи компьютерной графики. В 70-х это понятия появилось в контексте автоматизированного доказательства теорем и логического программирования, язык которого Prolog был разработанн Colmerauer \cite{colmerauer} и Kowalski \cite{kowalski}. В 80-х задачи разрешения ограничений были отнесены к логическому программированию, что образовало логическое программирование в ограничения (англ. constraint logic programming) \cite{jaffar_lassez}, \cite{dincbas}, \cite{colmerauer_2}.
\par Задача смешанного программирования имеет вид:
  $$c^* = \min\{c^Tx|Ax\le b,~ x\in \mathbb{Q}^n,~ x_j\in\mathbb{Z}~ \forall j\in\mathbb{I}\}$$
  $$X_{MIP}=\{x\in\mathbb{Q}^n|Ax\le b,~ x_j\in\mathbb{Z}~ \forall j\in\mathbb{I}\}$$
\par Решение $x^*$ называется оптимальным, если $c^* = c^Tx^*$.
\par Задача существования целочисленного решения системы является NP-полной. Таким образом, для реальных задач необходимо проделывать очень большой объем вычислений, что не позволяет расширить довольно ограниченный круг задач, для решения которых используются методы целочисленного программирования. Актуальность и трудность проблематики делают целочисленное программирование одним из перспективных и интересных направлений в математическом программировании \cite{karmanov}, \cite {balinski}.
\par Использование методов разрешения ограничений позволяет решать многие прикладные задачи, такие как планирование \cite{kautz} и теория расписаний \cite{barnier}, поддержка принятия решений \cite{saraev}, обработка изображений \cite{montanari}, тестирование интегральных схем \cite{hooker}, формальная верификация и статический анализ \cite{collavizza}, \cite{dick}, \cite{cormac}.
\par Существуют методы построения тестов с помощью символического выполнения (англ. symbolic execution). Такие методы используют символическое описание проходимого во время выполнения теста пути по коду программы в виде набора предикатов. Это описание позволяет выбирать новые тестовые ситуации так, чтобы они покрывали другие пути и строить тесты с помощью техник разрешения ограничений \cite{gotlieb}, \cite{boyapati}. 
\par В литературе можно найти несколько хороших обзоров с описанием методов решения задач разрешения ограничений \cite{kumar}, \cite{dechter_frost}, \cite{bartak}, \cite{meseguer}, \cite{miguel}, а также статьи в энциклопедических сборниках  \cite{dechter_networks}, \cite{hower}, \cite{mackworth}.
\par Более подробную информацию по теме разрешения ограничений можно найти в монографиях \cite{apt}, \cite{fruehwirth}, \cite{marriott}, \cite{rossi}, \cite{hentenryck}, \cite{hentenryck_michel_deville}, \cite{hentenryck_opl}, \cite{hentenryck_michel}. 
\par Линейные неравенства имеют большое самостоятельное значение, поскольку многие прикладные задачи, в том числе из области экономики \cite{kantorovich}, представляются в виде таких систем. 
\par Нас интересует подраздел линейного программирования - целочисленное линейное программирование (англ. integer linear programming, ILP), в котором на все или некоторые (смешанное целочисленное программирование) переменные накладывается ограничение целочисленности. 
\par Наиболее известные из задач целочисленного программирования — задача выбора маршрута (задача коммивояжера, задача почтальона), задача о максимальном паросочетании, задача погрузки товара и т. д. На практике могут решаться проблемы ремонта двигателей самолёта, анализ структуры кристаллов и др. \cite{matai} 
\par К задаче ЦЛП также сводятся задачи из области компиляторных технологий: распределения регистров и планирования командного исполнения при компилировании \cite{chang}, анализ зависимостей по данным \cite{libby}.
\par GPU имеет много большее количество энергоэффективных ядер, созданных для массивно параллельного программирования на больших объёмах данных. Представляется актуальным использовать возможности GPU для задачи разрешения ограничений. Таким образом направление вычислений эволюционирует от «централизованной обработки данных» на центральном процессоре до «совместной обработки» на CPU и GPU. Всё чаще GPU применяется для решения вычислительных задач, выходящих за рамки первоначального предназначения этих устройств. В связи с чем в работе исследуются возможности графических карт применительно к задаче целочисленного программирования. 
\par Технология GPGPU (general-purpose computing for graphics processing units) позволила увеличить на несколько порядков вычислительные возможности компьютеров, пропорционально уменьшив затраты на программное обеспечение. Она позволяет использовать ресурсы видеокарт для неграфических вычислений. Основным производителем видеокарт с аппаратной поддержкой GPGPU является NVIDIA с комплексом CUDA, которая обеспечила рост популярности GPGPU за счёт упрощения процесса создания программ, использующих возможности GPU. Ещё одной популярной реализацией техники GPGPU является OpenCL (open computing language) - фреймворк для написания программ на различных графических и центральных процессорах. Далее в работе рассматривается технология Cuda.


\section{Постановка задачи}

Цель работы - реализация алгоритма Branch-and-Cut с использованием подходов массивного параллелизма и возможностей Nvidia CUDA. Для достижения цели были поставлены следующие задачи: 
  \begin{itemize}
  \item[•] Провести обзор метода решения задачи ЦЛП - Branch-and-Cut.
  \item[•] Реализовать алгоритм Branch-and-Cut последовательно на CPU.
  \item[•] Исследовать алгоритм Branch-and-Cut на наиболее часто повторяющиеся вычисления.
  \item[•] Исследовать возможности распараллеливания найденных участков на GPU.
  \item[•] Реализация параллельного алгоритма Branch-and-Cut, учитывая особенности CUDA.
  \item[•] Экспериментальный и теоретический анализ предложенного решения.
  \end{itemize}


\section{Обзор существующих решений}

Так как методы решения задач смешанного целочисленного программирования представляют большой коммерческий интерес, наибольшего прогресса в этой области добились коммерческие разработчики, включая Cplex от IBM ILOG, Lingo от Lindo Systems Inc. и Xpress от FICO. Но разработанный код скрыт правообладателями. 
\par К методам целочисленного линейного программирования относят:
  \begin{itemize}
  \item[•] метод отсечений (например, метод Гомори);
  \item[•] приближённый метод (прямой алгоритм, предложенный Р.Д.Юнгом и Ф.Гловером)
  \item[•] метод ветвей и границ (Branch-and-Bound);
  \item[•] комбинированные методы (Branch-and-Cut или Cut-and-Branch);
  \item[•] использование абсолютной унимодулярности матрицы (сильно ограничивает множество решаемых систем уравнений);
  \item[•] эвристики:
    \begin{itemize}
    \item табу-поиск - tabu-search \cite{glover};
    \item алгоритм восхождение на вершину - hill climbing \cite{russell};
    \item алгоритм имитации отжига \cite{kirkpatrick};
    \item муравьиный алгоритм \cite{colorni};
    \item нейронная сеть Хопфилда \cite{lau};
    \end{itemize}
  \end{itemize}
\par Недостатком эвристических методов является то, что если алгоритм не может найти решение, то невозможно определить, нет решения или есть, но алгоритм не смог его найти. 


\chapter{Методика решения задачи}

\section{Метод ветвей и границ}

Метод ветвей и границ (англ. Branch-and-Bound) - это метод комбинаторной оптимизации для решения задач целочисленного программирования, то есть таких задач, решение которых целочисленно.  Для метода ветвей и границ необходимы две процедуры: ветвление и нахождение оценок (границ). Процедура ветвления состоит в разбиении множества допустимых значений переменной $x$ на подобласти (подмножества) меньших размеров. Процедуру можно рекурсивно применять к подобластям. Полученные подобласти образуют дерево, называемое деревом поиска или деревом ветвей и границ. Вершинами этого дерева являются построенные подобласти.
\par Метод использует решение системы линейных неравенств без наложения ограничения целочисленности - релаксационных задач, которые имеют вид: 
  $$\hat c = \min \{c^Tx \mid Ax\le b,~ x\in\mathbb{Q}^n\}$$
\par $X_{LP} = \{x \in \mathbb{Q}^n \mid Ax \le b\}$ - множество допустимых значений. 
\par В приведённом ниже алгоритме Branch-and-Bound используются обозначения: $L$ - множество активных задач, $R$ - начальная задача. 
  \begin{enumerate}
  \item[{[init]}] $L = \{R\}$, $\hat c = \infty$;
  \item[{[abort]}] if $L = \emptyset$, return $x^*=\hat x$, $c^* = \hat c$;
  \item[[{select]}] выбрать $Q\in L$, $L = L \backslash \{ Q \}$;
  \item[[{solve]}] решить $Q_{relax}$ - задачу $Q$ без ограничения целочисленности. Если нет решения, то $\bar c = \infty$. Иначе имеет оптимальное решение $\bar x$ и соответствующее значение $\bar c$;
  \item[{[bound]}] if $\bar c \ge \hat c$, goto [abort];
  \item[{[check]}] if $\bar x$ целочисленное, то $\hat x = \bar x$, $\hat c = \bar c$, и goto [abort];
  \item[{[branch]}] разбить $Q$ на подзадачи $Q = Q_1 \cup \dots \cup Q_k$, $L = L \cup \{Q_1 \cup \dots \cup Q_k \}$ и goto [abort].
  \end{enumerate}
\par Рис.~\ref{ris:branching} иллюстрирует, как происходит разбиение задачи в алгоритме на стадии [branch].
\par
  \begin{figure}[h]
  \center{\includegraphics[width=1\linewidth]{branching}}
  \caption{Разбиение задачи $Q$ на подзадачи $Q_1 \cup \dots \cup Q_k$}
  \label{ris:branching}
  \end{figure}
\par Уточним, на какие задачи разбивается общая задача. Наиболее популярный метод состоит в выборе переменной, по которой мы ветвимся, а задачи $Q = Q_1 \cup Q_2$, где $Q_1 = Q \cap \{x_j \le \lfloor \bar x_j \rfloor \}$ и $Q_2 = Q \cap \{x_j \ge \lceil \bar x_j \rceil \}$. Более сложное ветвление или ветвление на большее количество подзадач редко используется, тем не менее в некоторых задачах также может быть эффективным \cite{borndoerfer}, \cite{clochard}, \cite{naddef}.
\par До сих пор остаётся открытым вопрос о стратегии выбора переменной для процедуры ветвления. К сожалению, нет оптимального метода и для выбора хорошей стратегии опираются на вычислительный эксперимент. 
\par Опишем наиболее популярные методы ветвления:
  \begin{itemize}
  \item[•] Ветвление по переменной, значение которой наиболее близко к целому значение или наиболее далеко от него:
    \begin{itemize}
    \item стандартное правило, наиболее простое;
    \item не всегда эффективно. 
    \end{itemize}
  \item[•] Сильное ветвление:
    \begin{itemize} 
    \item каждая переменная проверяется на наибольшее влияние на целевую функцию, т.е. при ветвлении по которой, фукнция изменится максимально
    \item метод включает в себя преждевременное решение некоторых задач без ограничения целочисленности и выбирает лучшее;
    \item эффективно относительно размера дерева задач, но затратно относительно времени.
    \end{itemize}
  \item[•] Ветвление с учётом превдостоимости:
    \begin{itemize}
    \item сохраняются треки каждой из переменных и выбирается та, изменение которой, возможно наибольшее, т.е. которая обладает наибольшей псевдостоимостью;
    \item попытка оценить стоимость ветвления, основываясь на истории ветвления по данной переменной;
    \item неэффективно в начале алгоритма.
    \end{itemize}
  \end{itemize}
\par Здесь приведены не все. Для более исчерпывающего исследования методов ветвления можно обратиться к \cite{land_powell}, \cite{linderoth}, \cite{fuegenschuh}.
\par Основные способы выбора узла в дереве задач, каждый из которых имеет свои преимущества:
  \begin{itemize}
  \item[•] Обход дерева в глубину \cite{dakin} всегда выбирает дочернюю подзадачу относительно нынешней.
  \item[•] Выбор лучшей задачи (более подробно описан в параграфе 3.4).
  \end{itemize}


\section{Симплекс-метод}

Решать релаксационную задачу в алгоритме Branch-and-Bound можно симплекс-методом.
\par Симплекс-метод - это алгоритм решения оптимизационной задачи линейного программирования, путём перебора вершин выпуклого многогранника в многомерном пространстве \cite{dantzig}. 
\par Прямой симплекс метод решает задачу:
  $$c^Tx \rightarrow \max,~ Ax \le b,~ x \ge 0,~ b \ge 0.$$
\par Двойственный симплекс-метод решает задачу:
  $$c^Tx \rightarrow \max,~ Ax \le b,~ x \ge 0,~ c \ge 0.$$
\par Алгритм симплекс-метода состоит из трёх частей: поиск строки, поиск столбца, трансформация матрицы:
  \begin{enumerate}
  \item[1.] Поиск строки - pivot\_row:
    \begin{enumerate}
    \item[а)] ищем первый отрицательный элемент, кроме нулевого, в нулевом столбце;
    \item[б)] если его нет, завершаем алгоритм.
    \end{enumerate}
  \item[2.] Поиск столбца:
    \begin{enumerate}
    \item[а)] не считая нулевого элемента, ищем отрицательные элементы в pivot\_row и сохраняем колонну, которой принадлежит этот элемент и нормированную по модулю данного элемента, в некотором временном множестве $P$;
    \item[б)] выбираем лексикографически наименьшую колонну из множества $P$ - pivot\_col.
    \end{enumerate}
  \item[3.] Трансформация матрицы - применяем гауссовы преобразования таким образом, чтобы pivot\_row обнулилась, кроме элемента, соответствующего pivot\_col. После преобразований этот элемент должен быть равен -1.
  \end{enumerate}


\section{Метод отсечений}

Метод Branch-and-Bound может быть усовершенствован методами отсечений. Отсечениями называют линейные неравенства, которые удовлетворяются целочисленными решениями задачи линейного программирования, но могут нарушаться решениями общей задачи оптимизации. \par Метод отсечений приближает решение к целочисленному методом сведения исходной допустимой области к выпуклой оболочке её одпустимых целочисленных точек. 
\par Таким образом в алгоритме Branch-and-Bound мы усиливаем релаксационную задачу. Отсечение добавляется на основе результата решения предыдущей релаксационной задачи.
\par Наибольший вклад в исследование области отсечений внёс Гомори \cite{gomory_1}, который доказал что целочисленная задача может быть решена за конечное число шагов с помощью одного подхода отсечений без ветвления \cite{gomory}. К сожалению, предложенные им отсечения не были эффективными и медленно сходились, поэтому идея отсечений не рассматривалась много лет. Но спустя некоторое время работа Balas \cite{balas_ceria_corn_natraj} 1996 г. показала что метод отсечений может быть более эффективным при соединении с методом Branch-and-Bound. Наиболее подробное описание методов можно найти в \cite{klar}, \cite{wolter}, \cite{marchand}, \cite{fuegenschuh}.

\par Способы построения отсечений:
  \begin{itemize}
  \item[•] mixed integer rounding cuts \cite{nemhauser_wolsey};
  \item[•] gomory mixed integer \cite{gomory};
  \item[•] lift-and-project cuts \cite{balas_ceria_corn}, \cite{balas_ceria_corn_1};
  \item[•] lifted cover cuts \cite{balas}, \cite{balas_zemel}, \cite{martin_weismantel};
  \item[•] GUB cover cuts \cite{wolsey};
  \item[•] complemented mixed integer rounding cuts \cite{marchand_wolsey};
  \item[•] strong Chvátal-Gomory cuts \cite{chvatal}, \cite{letchford_lodi};
  \item[•] flow cover cuts \cite{padberg}, \cite{van_roy}.
  \end{itemize}
\par В \cite{mitchell} подробно разобран пример решения двумерной задачи целочисленного программирования методом Branch-and-Bound и методом отсечений, проиллюстрированный на рис.~\ref{ris:example}.
\par
  \begin{figure}[h]
  \center{\includegraphics[width=1\linewidth]{example}}
  \caption{Пример решения двумерной задачи методом Branch-and-Cut}
  \label{ris:example}
  \end{figure}


\section{Используемый метод}

Решается задача линейного программирования в виде:
  $$Ax \le b$$
  $$x \ge 0$$
\par На вход алгоритму подаётся матрица коэффициентов $A$ размера $m \times n$. Сначала к матрице добавляется отрицательная единичная матрица. 
  $$\bar A = \left[ 
  \begin{tabular}{l}
  $-E$\\
  $A$
  \end{tabular}
  \right]$$
\par Так учитывается положительность переменных.
\par Как известно, метод ветвления на основе псевдостоимости является наиболее эффективным относительно времени исполнения программы, но при этом может быть использован не сначала программы. В начале алгоритма используем метод наипростейшего ветвления. То есть относительно значения наименее близкого к целочисленному. 
\par Выбор соответствующего отсечения совершался на основе результатов вычислений, приведённых в \cite{achterberg}, таким образом был выбран метод MIR (англ. mixed integer rounding cuts).
\par На каждом шаге, кроме первого, решается одновременно две задачи, которые являются дочерними относительно одного и того же родителя. Поэтому на каждой итерации необходимо выбирать уже решённую задачу, чтобы решать её дочерние.
\par Такой подход неэффективен, если реализовывать задачу последовательно. Но массивное распараллеливание даёт нам возможность решать такие задачи одновременно. Отсюда и нестандартный метод выбора следующей решаемой задачи - по максимальному количеству целых переменных. 
\par Так как оптимальное решение после отсечения не является допустимым решением новой задачи линейного программирования, но является её двойственным допустимым решением, то для решения новой задачи выгоднее использовать двойственный симплекс-метод. Кроме того, так как правильное отсечение явлется неравенством, то удобнее использовать столбцовую форму записи и считать, что ограничения исходной задачи заданы в форме неравенств \cite{shevchenko}.
\par Внутри симплекс-метода выбор строки совершается по первой строке с наименьшим индексом. Таким образом, если добавить отсечение или ветвление в конец матрицы, то симплекс-метод сначала пройдёт все итерации, что первая матрица. Отсюда идея оптимизации алгоритма с помощью матрицы трансформации. Обозначим её через $T$, допустим вследствие симплекс-метода за $k$ итераций матрица $\bar A$ изменилась:
  $$\left[
  \begin{tabular}{l}
  $-E$\\
  $A$
  \end{tabular}
  \right]
  \times
  T=
  \left[
  \begin{tabular}{l}
  $-T$\\
  $A'$
  \end{tabular}
  \right]$$
\par Тогда при добавлении отсечений к матрице $\bar A$, обозначим их $C$, за те же $k$ итераций изменения выглядят так:
  $$\left[
  \begin{tabular}{l}
  $-E$\\
  $A$\\
  $C$
  \end{tabular}
  \right]
  \times
  T=
  \left[
  \begin{tabular}{l}
  $-T$\\
  $A'$\\
  $C'$
  \end{tabular}
  \right]$$
\par Используя эти свойства, после первого шага мы получаем матрицу трансформацию. И на следующих шагах перемножаем её с матрицами отсечений и запускаем в симплекс с $k+1$ шага. 
\par Реализованный алгоритм:
\par\textit{Input} Матрица коэффициентов линейных ограничений.
\par\textit{Output} Вектор целочисленных значений переменных или констатация, что таковых нет.
\begin{itemize}
\item[{[simplex]}] симплекс-метод применяется к входной матрице, если решения нет - return нет целочисленного решения, иначе инициализируем матрицу трансформации; 
\item[{[branch]}] ветвимся и определяем место решённой задачи в очереди, если нет переменных ветвления, то return целочисленное решение; 
\item[{[order]}] если в очереди больше нет задач, то return нет целочисленного решения, следующая в очереди задача имеет максимальное число целых переменных; 
\item[{[init]}] инициализируем дочерние задачи выбранной решённой;
\item[{[simplex]}] решаем задачи, используя симплекс-метода;
\item[{[delete]}] если одна из задач или обе не имеют решения, удаляем ветку дерева;
\item[{[cuts]}] если задача имеет решения и среди переменных решения есть нецелочисленные, проверяем задачу на возможность добавления отсечений, если таковые есть - снова решаем задачу;
\item[{[loop]}] переходим в пункту [branch]
\end{itemize}
\par Описанный выше алгоритм не решает задачу оптимизации, поэтому завершается, как только находится первое целочисленное решение. А целевая функция может быть любой. 


\chapter{Практическая реализация метода} 
 
язык программирования, технология CUDA, компилятор, количество строчек кода )) Текущая версия содержит столько-то строчек кода. 


\section{Сравнение GPU и CPU} 

Важно понимать различия между тем, как спроектированы CPU и GPU, которые изначально предназначены для разных типов вычислений. Поэтому прежде, чем перейти к CUDA, рассмотрим эти различия. Наиболее важные из них это модель управления нитями и отличия физической памяти.
\par CPU поддерживает выполнение сильно ограниченного числа совместно выполняющихся нитей. Серверы, содержащие 4 шестиядерных процессора, могут паралелльно исполнять лишь 24 нити параллельно (или 48 если ЦПУ поддерживет гиперпоточность). В это время наименьшее объединение потоков на видеокарте содержит 32 нити, что называется варпом. Современные карты NVIDIA поддерживает до 1536 активных нитей на один мультипроцессор \cite{features}. Если видеокарта содержит 16 мультипроцессоров, то число может превышать 24 000 (Рис.~\ref{ris:compare}).
\par
  \begin{figure}[h]
  \center{\includegraphics[width=1\linewidth]{compare_paper}}
  \caption{Сравнение GPU и CPU}
  \label{ris:compare}
  \end{figure}
\par Многопоточность в графических процессорах реализована на аппаратном уровне. Ядра GPU проектируются для большого числа параллельно выполняемых инструкций, в то время как ядра CPU созданы для исполнения одного потока последовательных инструкций с максимальной производительностью. Ядра CPU используют MIMD-архитектуру – множественный поток команд и данных. Каждое ядро работает отдельно от остальных, исполняя разные инструкции для разных процессов. GPU используют SIMD-архитектуру (одиночный поток команд, множество потоков данных) и специально рассчитанные на работу с ней контроллеры памяти. Ядра мультипроцессора в GPU исполняют одни и те же инструкции одновременно. 
\par На CPU каждое переключение между потоками неизбежно ведёт к значительным временным задержкам продолжительностью в несколько сотен тактов. В то же время GPU легко переключается между нитями. Если происходит задержка на одном варпе, GPU начинает исполнение другого. Благодаря тому, что каждая нить содержит свои регистры, нет необходимости в перезаписи регистров при каждом переключении. Ресурсы распределены для каждой нити отдельно, пока не завершается её исполнение. 
\par Память CPU и GPU, как правило, расположена отдельно и соединена шиной PCI Express. 
\par В цетнральных процессорах большие количества транзисторов и площадь чипа идут на буферы команд, аппаратное предсказание ветвления и огромные объёмы начиповой кэш-памяти. Все эти аппаратные блоки нужны для ускорения исполнения немногочисленных потоков команд. Видеочипы тратят транзисторы на массивы исполнительных блоков, управляющие потоками блоки, разделяемую память небольшого объёма и контроллеры памяти на несколько каналов. Вышеперечисленное не ускоряет выполнение отдельных потоков, но позволяет чипу обрабатывать несколько тысяч потоков, одновременно исполняющихся чипом и требующих высокой пропускной способности памяти \cite{poletaev}.
\par CPU, будучи универсальным вычислительным устройством, эффективно справляется с целым спектром различных задач, в то время как предназначение графических процессоров гораздо более узконаправленное. В задачах с множественными ветвлениями и переходами графический процессор не столь эффективен как центральный.
\par В связи с особенностями графических процессор они хорошо справляются с задачами, где требуется большое количество параллельных вычислений с большим количеством арифметических операций. Причем элементы данных должны быть независимы (GPU обладает плохим синхронизационным аппаратом) и работа над данными одинакова. 
\par Такой стиль программирования является обычным для графических алгоритмов и многих научных задач, но требует специфического программирования. Зато такой подход позволяет увеличить количество исполнительных блоков за счёт их упрощения.


\section{Технология CUDA}

CUDA (Compute Unified Device Architecture) является архитектурой параллельных вычислений от NVIDIA, позволяющей существенно увеличить вычислительную производительность благодаря использованию GPU (графических процессоров). Для реализации новой вычислительной парадигмы компания NVIDIA изобрела архитектуру параллельных вычислений CUDA, и обеспечивающую необходимую базу разработчикам ПО.
\par Программирование на CUDA включает в себя код на двух различных платформах совместно: host на одном или нескольких CPU и device на одном или нескольких NVIDIA GPU, поддерживающих CUDA.
\par Платформа параллельных вычислений CUDA обеспечивает набор расширений для языков C и С++, позволяющих выражать как параллелизм данных, так и параллелизм задач на уровне мелких и крупных структурных единиц. Всё это является несомненными преимуществами использования CUDA-технологии на ряду с доступностью.
\par Компания NVIDIA предоставляет показательные примеры кода на CUDA \cite{sanders} в свободной доступе на английском языке и в продаже на русском, а также как проводить подробную оптимизацию кода \cite{cuda_best}. В том числе предоставляются две платформы Nvidia Nsight Edition для разработчиков в Eclipse и Microsoft Visual Studio. Дополнительную информацию также можно найти в \cite{kirk}, \cite{boreskov}.
\par Перечислим основные характеристики CUDA:
  \begin{itemize}
  \item[•] Унифицированное программно-аппаратное решение для параллельных вычислений на видеочипах NVIDIA.
  \item[•] Большой набор поддерживаемых графических плат (от мобильных до мультичиповых).
  \item[•] В качестве языка программирования используется расширенный вариант языка C.
  \item[•] Поддерживает взаимодействие с графическими API OpenGL и DirectX.25
  \item[•] Имеется поддержка 32- и 64-битных операционных систем: Windows XP, WindowsVista, Linux и MacOSX.
  \item[•] Возможность разработки на низком уровне.
  \item[•] CUDA обеспечивает доступ к быстрой разделяемой памяти, которая может быть использована для межпоточного взаимодействия.
  \item[•] Нативный компилятор/отладчик: nvcc/cuda-gdb[linux/mac os], расширение к msvc/TotalView [win]. 
  \end{itemize}
\par Команда разработчиков CUDA  создала набор программных уровней для работы с GPU, которые отображены на Рис.~\ref{ris:cuda_levels}. Как можно видеть, CUDA обеспечивает два API:
  \begin{itemize}
  \item высокоуровневый API: CUDA Runtime API;
  \item низкоуровневый API: CUDA Driver API;
  \end{itemize}
\par
  \begin{figure}[h]
  \center{\includegraphics[width=1\linewidth]{cuda_levels}}
  \caption{Набор программных уровней для работы с GPU}
  \label{ris:cuda_levels}
  \end{figure}
\par Каждый вызов фукнции уровня Runtime состоит из более элементарных инструкций уровня Driver API. Стоит помнить, что два API взаимно исключают друг друга. При использовании одного, нельзя использовать функции другого уровня. Driver API сложнее и требует больше знаний о NVIDIA GPU, но при этом он более гибок и предоставляет весь контроль программисту. 
\par Потоком в CUDA назвается базовый набор данных, который требуется обработать. В отличие от потоков CPU, переключение контекста между двумя потоками CUDA не является ресурсоёмкой операцией. 32 потока объединяются в один варп (англ. warp) - минимальный объём данных, обрабатываемых SIMD-способом в мультипроцессорах CUDA. Вследствие этого, даже при ветвлении внутри программы все нити внутри одного warp'а исполняют сначала одну ветку, а затем другую. 
\par Также потоки составляют блоки, которые в свою очередь формируют сетки. Если GPU имеет мало ресурсов, то он будет выполнять блоки последовательно. 
\par Физический уровень - видеокарта:
  \begin{itemize}
  \item[•] Streaming Multiprocessor (SM) - “процессор” на видеокарте.
  \item[•] Bandwidth – внутренняя пропускная способность. Влияет на копирование dev-dev.
  \item[•] PCI-express - шина общения с хостом. Влияет на скорость копирования host-dev.
  \end{itemize}
\par Логический уровень - kernel (ядро) - функция, полностью вычисляющаяся на графическом устройстве (Рис.~\ref{ris:thread_block}):
  \begin{itemize}
  \item[•] Grid (геометрия сетки блоков нитей) – свойство запуска функции, определяющее количество запускаемых блоков вычислений. Важна как сама геометрия, так и максимизация количества.
  \item[•] Thread block (блок нитей) - множество нитей, имеющих общую r/w память, со scope адресации внутри этого блока.
  \item[•] Warp – множество одновременно исполняющихся нитей внутри одного cuda core. Имеет особый смысл в случае ветвлений: блок нитей бьется на две части, которые исполняются по сути последовательно. Также понятие warp сильно связано с выравниваниями в памяти.
  \end{itemize}
\par
  \begin{figure}[h]
  \center{\includegraphics[width=0.63\linewidth]{thread_block}}
  \caption{Конструкция grid}
  \label{ris:thread_block}
  \end{figure}
\par Видеокарта может содержать несколько (от 2 до 2000) потоковых мультипроцессоров (streaming multiprocessor) (Рис.~\ref{ris:tpc}). Они в свою очередь содержат восемь вычислительных устройств и два суперфункциональных устройства SFU (Super Function Unit), где инструкции выполняются по принципу SIMD, что в данном случае означает применение одной инструкции ко всем потокам в варпе.
\par
  \begin{figure}[h]
  \center{\includegraphics[width=0.7\linewidth]{tpc}}
  \caption{Конструкция TPC и SM}
  \label{ris:tpc}
  \end{figure}
\par Потоковые мультипроцессоры работают следующим образом: каждый такт начало конвейера выбирает варп, готовый к выполнению, и запускает выполнение инструкции. Чтобы инструкция применилась ко всем 32 потокам в варпе, концу конвейера потребуется четыре такта, но поскольку он работает на удвоенной частоте по сравнению с началом, потребуется только два такта (с точки зрения начала конвейера). Поэтому, чтобы начало конвейера не простаивало такт, а аппаратное обеспечение было максимально загружено, в идеальном случае можно чередовать инструкции каждый такт, классическая инструкция в один такт и инструкция для SFU в другой.
\par Мультипроцессор имеет 8192 регистра, которые общие для всех потоков всех блоков, активных на мультипроцессоре. Число активных блоков на мультипроцессор не может превышать восьми, а число активных варпов ограничено 24 (768 потоков).
\par Если распараллеливать задачу на CPU, то следить за потоками нужно самим. При распараллеливании на видеокартах известен только номер нити или блока. А также регулируется количество потоков, которые все исполняют одну последовательность инструкций. Запуск с хоста device-функции - это kernel. У этого ядра существует конфигурация. Внутри блока нити находятся физически близко и могут делить общую память. Адресация внутри сетки блоков происходит по идентификации блоков и нитей.
\par Эффективность распараллеливания на GPU также предъявляет требования к данным. Наибольшая производительность достигается на больших однотипных объёмах данных, над которыми производятся одинаковые операции. Таким образом используются тысячи или десятки тысяч параллельных потоков, чтобы GPU не простаивало. 
\par Также желательно, чтобы память, используемая рядом расположенными нитями, располагалась последовательно. Некоторые шаблоны доступа к памяти позволяют аппаратным средствам объединять группы считываний или записи нескольких элементов данных в одну операцию. Данные, расположенные недостаточно близко, будут способствовать замедленнию при использовании на CUDA.
\par Для использования данных на CUDA необходимо переместить их из памяти host на device через шину PCI Express. Такие перемещения затратны и должны быть минимизированы. Поэтому использование CUDA, если задействовано малое количество нитей, не даст выигрыша в такой ситуации.
\par Оптимизация программы CUDA также состоит в получении оптимального баланса между количеством блоков и их размером. Больше потоков на блок будут полезны для снижения задержек работы с памятью, но и число регистров, доступных на поток, уменьшается. Более того, блок из 512 потоков будет неэффективен, поскольку на мультипроцессоре может быть активным только один блок, что приведёт к потере 256 потоков. Поэтому NVIDIA рекомендует использовать блоки по 128 или 256 потоков, что даёт оптимальный компромисс между снижением задержек и числом регистров для большинства ядер/kernel.
\par За формирование и компиляцию ядер отвечает CPU. Видеочип просто
принимает уже скомпилированное ядро и создает его копии для каждого
элемента данных. Каждое из ядер исполняется в своем собственном потоке.


\section{Иерархия памяти}

  \begin{figure}[h]
  \center{\includegraphics[width=0.7\linewidth]{mem_hierarchy}}
  \caption{Иерархия памяти CUDA}
  \label{ris:mem_hierarchy}
  \end{figure}
\par Вычислительные возможности начиная с 2.x:
  \begin{itemize}
  \item[•] Глобальная память (чтение и запись):
    \begin{itemize}
    \item медленная, но может быть кеширована;
    \item последовательное и выровненное чтение по 64 или 128 байт для более быстрого использования. Иначе замедление в 10-100 раз;
    \item плохая параллельная скорость доступа, если пользоваться ей напрямую;
    \item адресация - прямая, по указателям;
    \item видна всей сетке блоков. 
    \end{itemize}
  \item[•] Текстурная память (только чтение) - кэш, оптимизированный для двумерного доступа.
    \begin{itemize}
    \item более удобный метод доступа с геометрической точки зрения;
    \item неизменяемая;
    \item кэшируемая.
    \end{itemize}
  \item[•] Константная память:
    \begin{itemize}
    \item содержит константы и аргументы функций ядра;
    \item имеет особенные инструкции заполнения;
    \item сравнительно быстрая, но её мало;
    \item видна всей сетке блоков. 
    \end{itemize}
  \item[•] Разделяемая память (48кБ на 1 SM):
    \begin{itemize}
    \item быстрая, но подвержена конфликтам в банке памяти;
    \item видна всем нитям внутри блока.
    \end{itemize}
  \item[•] Локальная память:
    \begin{itemize}
    \item используется для любых данных, что не влезли в регистровую память;
    \item часть глобальной памяти, поэтому медленная;
    \item автоматическое выравнивание обращений;
    \item видна одной нити.
    \end{itemize}
  \item[•] Регистровая память - 32768 32-битных регистра на 1 SM.
  \end{itemize}
\par Константная память целиком кэшируется. Поэтому получается достаточно быстро. У каждой нити свои регистры. Локальные переменные могут попасть как в shared так и global. Блоки обрабатываются конвейерным образом. shared память очень быстрая. аллоцируется статически. 
\par Два потока из разных блоков не могут обмениваться информацией между собой во время выполнения. Пользоваться общей памятью не так просто. Общая память всё оправдана за исключением случаев, когда несколько потоков пытаются обратиться к одному банку памяти, вызывая конфликт. 
\par Мультипроцессоры также могут обращаться к видеопамяти, но с меньшей пропускной способностью и большими задержками. Поэтому NVIDIA оснастила мультипроцессоры кэшем, хранящим константы и текстуры. 
\par Доступ к глобальной памяти имеет свои трудности. Выравнивание доступа к памяти – самый сложный и самый важный аспект в программировании под Nvidia CUDA. Доступ к памяти называется coalesced в том случае, когда массовая операция доступа из одного warp к памяти укладывается в одну транзакцию.
\par Для обмена информацией внутри блока между потоками используется разделяемая память (англ. shared memory). РРазделяемая память устроена так, что доступная блоку память разбита на банки памяти с раздельными путями доступа. В случае, если две нити пытаются обратиться в один банк памяти одновременно, возникает “конфликт” и доступ они получают последовательно, а не параллельно. Максимальное количество нитей в блоке, пытающихся обратиться к одному банку, называется “глубиной конфликта доступа”.
\par Для интегрированных GPU использование нуль-копируемой памяти всегда даёт выигрыш, потому что эта память в любом случае физически разделяется с CPU. В тех случаях, когда входные и выходные буферы используются ровно один раз, повышение производительности будет наблюдаться и на дискретном GPU.
\par Наибольший выигрыш в том числе может быть достигнут за счёт асинхронизации копирования и исполнения ядра. Примеры, иллюстрирующие это, подробно описаны в \cite{sanders} и \cite{cuda_best}. 
\par Обозначенное угловыми скобками ядро также принимает необязательный аргумент - номер потока исполнения (англ. stream). Этот запуск ядра выполняется асинхронно и используется с фукнциями асинхронного копирования памяти. Они выполняются параллельно друг другу и паралельно коду CPU. Поэтому не исключено, что последующий код CPU начнёт выполнятся ещё до того, как закончится копирование памяти или исполнение ядра. Для этого в CUDA существуют функции синхронизаци. Гарантируется лишь, что операции копирования и исполнения ядра, помещённые в один и тот же поток, будут выполняться последовательно. То есть поток ведёт себя как упорядоченная очередь задач для GPU. Подробнее об этом можно узнать в \cite{cuda_guide} и найти примеры в \cite{sanders}


\section{Программная реализация}

Исследуем последовательный код на CPU на места, наиболее эффективно поддающиеся рапараллеливанию. Для этого обратимся к профайлеру gprof. Ниже приведены результаты исполнения только для функций, исполнение которых составляет больше 0.009 процентов от общего времени.
\\
\begin{tabular}{rrrrrrp{3cm}}
  \% &  cumul. &  self    & &         self  &   total    \\       
 time  & seconds &  seconds  &  calls &  s/call &  s/call & name    \\
 99.67  &   13.21  &  13.21 &   22756 &    0.00 &    0.00 & dualSimplex\\
  0.38  &   13.26  &   0.05  &  22756 &    0.00  &   0.00 & pivotColumn\\
  0.08   &  13.27 &    0.01 & 13986754 &    0.00 &    0.00 &  cmp\\
\end{tabular}
\par Как видно из таблицы, в первую очередь необходимо оптимизировать метод трансформации матрицы. Во-вторых, оптимизировать произведение матриц. 
\par Уже существуют известные оптимизации произведения матриц. Можно воспользоваться обучающим алгоритмом из \cite{cuda_best_matr}, а также уже известной реализацией из библиотеки cuBLAS на GPU, которая есть аналог функции BLAS на CPU. 
\par BLAS (Basic Linear Algebra Subprograms) - интерфейс, базовые подпрограммы линейной алгебры:
  \begin{enumerate}
  \item Векторные операции вида $y\Leftarrow\alpha x + y$ - операции скалярного произведения, взятия нормы вектора и др.
  \item Операции матрица-вектор вида $y\Leftarrow\alpha Ax + \beta y$, решение $Tx = y$ для $x$ с треугольной матрицей $T$ и др.
  \item Операции матрица-матрица вида $C\Leftarrow \alpha AB + \beta C$, решение $B\Leftarrow \alpha T^(-1)B$ для треугольной матрицы $T$ и др.
  \end{enumerate}
\par В работе были разработаны послд и  парал версия алгоритма BAC. Описание последовательной версии. Алгоритм соответствует описанию из раздела. Реализация на языке. Число строк такое-то (утилиту погуглить). 


Разработка парал. версии базировалась на анализе наиболе ... фрагментов. Для анализа был использован тест. От тестов результат не зависит. Результаты проф приведены в таблице. ссылочку к профайлеру. Использовать прошедшее время. Не надо уже существует. 

Парал отличается реализацией таких-то функций. Описать также точки откуда вызывается код. Аннотировать код. 

\chapter{Анализ метода}

\section{Экспериментальный анализ корректности метода}

Первоначально при выборке тестов учитывался так же факт того, что важен анализ как эффективности, так и корректности. В работе корректность алгоритма устанавливается при помощи сравнительных тестов в формате DIMACS, которые представляют собой КНФ формулу. Задача выполнимости сводится к нахождению булевого решения (а при добавлении ограничений $x_i <= 1$ и $x_i >= 0$ к нахождению целочисленного решения) некоторой системы линейных уравнений, составленных на основании КНФ формулы. Таким образом мы проверяем корректность алгоритма, зная выполнима формула или нет.


\section{Экспериментальный анализ эффективности метода}

Было проведено более подробное исследование эффективности выбранного метода. Оно состояло из трёх этапов:
  \begin{enumerate}
  \item[1.] Фиксируем количество ограничений и меняем количество переменных.
  \item[2.] Фиксируем количество переменных и меняем количество ограничений.
  \item[3.] Фиксируем отношение ограничений к переменным и меняем число переменных. 
  \end{enumerate}
\par Симплекс-метод широко используется и хорошо работает на практике: многочисленные эксперименты подтверждают почти линейную по числу переменных оценку числа итераций. Однако можно показать, что на специальных примерах симплекс-метод (при некотором правиле выбора направляющего столбца и направляющей строки) работает экспоненциально долго. Первыми такой пример предложили Виктор Кли и Джордж Джеймс Минти в 1972 г.:
  $$\max(2^{n-1}x_1 + 2^{n-2}x_2 + 2x_{n-1} + x_n)$$
  $$\left\{ \begin{tabular}{lcr} 
  $x_1$ & $\leq$ & 5, \\
  $4x_1 + x_2$ & $\leq$ & 25, \\
  $8x_1 + 4x_2 + x_3$ & $\leq$ & 125, \\
  \multicolumn{3}{l}{\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots}\\
  $2^nx_1 + 2^{n-1}x_2 + 2^{n-2}x_3 + ... + 4x_{n-1} + x_n$ & $\leq$ & $5^n$,
  \end{tabular}\right.$$
\par В этом случае используемый в работе симплекс-метод выполнит $2^n-1$ итераций. Хотя для существуют другие правила выбора pivot\_row и pivot\_col, которые решают задачу за константное число операций, для них также существуют задачи, на которых алгоритм работает экспоненциально.
\par С другой стороны, алгоритмы решающие задачу линейного программирования за полиномиальное время существуют и, следовательно, она принадлежит классу $P$. Этот вопрос был решён в 1979 г. Л.Г.Хачияном, российским математиком. Он использовал метод эллипсоидов, разработанный для задач нелинейного программирования Н.З.Шором, Д.Б.Юдиным и А.С.Немировским. Хотя алгоритм Хачияна и его модификафии эффективны с теоретической точки зрени, практически конкурировать с симплекс-методом она, по крайней мере, пока, не могут. 
\par Наложив ограничение целочисленности на все или часть переменных, мы получаем задачу целочисленного линейного программирования, которая оказывается намного более трудной, чем задача линейного программирования. Задача о совместности условий задачи целочисленного программирования принадлежит классу $NP$-полных. 
\par Алгоритм Branch-and-Bound экспоненциально ($2^t$ итераций) зависит от длины записи коэффициентов задачи целочисленного линейного программирования:
  $$\max x_1$$
  $$\left\{ \begin{tabular}{l}
  $(2^t + 1)x_1=2^tx_2,$ \\
  $0\leq x_2 \leq 2^t,$ \\
  $x_1,x_2\in\mathbb{Z}.$
  \end{tabular}\right.$$
\par Для установления несовместности условий задачи целочисленного линейного программирования $$\max(x_1 + x_2 + ... + x_n)$$
  $$\left\{\begin{tabular}{l}
  $2x_1 + 2x_2 + ... + 2x_n = n$ \\
  $x_j\in\mathbb{Z}, (j=1,2,..,n)$
  \end{tabular}\right.$$
  где $n$ - нечётно, Branch-and-Cut требует $2^{\frac{n+1}{2}}$ итераций. Таким образом, трудоёмкость зависит от числа переменных. 
\par Мерой исследования эффективности на практике было выбрано время. Сводка результатов приведена ниже в таблице:


\section{Теоретический анализ метода}

Определим понятие масштабируемости. Масштабируемость (англ. scalability) означает способность системы, сети или процесса справляться с увеличением рабочей нагрузки (увеличивать свою производительность) при добавлении ресурсов (обычно аппаратных). 
\par Существует два показателя масштабируемости: сильная и слабая. Сильная масштабируемость показывает, как меняется время решения задачи с увеличением количества процессоров (или вычислительных узлов) при неизменном общем объёме задачи. Сильная масштабируемость определяется законом Амдала. Слабая масштабируемость показывает, как меняется время решения задачи с увеличением количества процессоров (узлов) при неизменном объёме задачи для одного процессора (или узла), и определяется законом Густафсона.
\par Закон Амдала может определить верхнюю грань ожидаемого ускорения за счёт увеличения количества процессоров с фиксированным объёмом задачи. Он выглядит как:
  $$S=\frac{1}{\left(1-P\right)+\frac{P}{N}}$$, где $S$ - ускорение выполнения программы, которое по определению равно отношению времени вычисления программы на одном процессоре ко времени вычисления на нескольких процессорах, $P$ - это доля исполнения части кода, которая может быть распараллелена, от общего времени исполнения всего кода, а $N$ - это количество процессоров, на которые может быть распараллелена исследуемая часть кода. Из формулы очевидно следует, что чем больше $N$, тем больше ускорение.
\par Исключим $N$ из формулы, устремив его к бесконечности. Отсюда $$S = \frac{1}{1-P}$$. В большинстве случаев программы не демонстрируют идеального ускорения. Но закон Амдала указывает на то, что для достижения ускорения стоит увеличивать распараллеливаемую часть. Если она маленькая, то программа не параллелизуема.
\par Закон Густафсона измеряет ускорение программы при увеличении количества процессоров и неизменном размере задачи на один процессор, т.е. объём задачи увеличивается пропорционально количеству процессоров. Он определяется формулой: $$S=N+(1-P(1-N)$$, где $P$ и $N$ принимают те же обозначения, что в формуле Амдала. 
\par Цель такого подхода - за заданное время выполнить максимальный объем вычислений.


\chapter{Результаты и выводы}

Привести здесь отзывы профайлера.
\par Вывод должен отражать коэффициент распараллеливаемости. То есть без учета того, что GPU как правило медленнее CPU, оцениваем отношение шагов. 


\section{Направления дальнейших исследований}


\bibliographystyle{utf8gost705u}
\bibliography{biblio} 

\end{document}
\grid
\grid
